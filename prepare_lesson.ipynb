{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34685688",
   "metadata": {},
   "source": [
    "# Parsing Text (aka Prepping Text Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a8a4c1",
   "metadata": {},
   "source": [
    "What is it?\n",
    "- Breaking our text data into smaller compenents and reduce variability between words\n",
    "\n",
    "Why do we care? \n",
    "- Allows us to better understand our data programatically and get us ready for explore and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ea28b",
   "metadata": {},
   "source": [
    "Workflow\n",
    "\n",
    "original text--->\n",
    "1. lowercase text\n",
    "2. remove accented and non-ASCII characters\n",
    "3. remove special characters\n",
    "4. tokenize the strings into discrete units\n",
    "5. stem/lemmatize words\n",
    "6. remove stopwords\n",
    "\n",
    "ready for exploration!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe7c252",
   "metadata": {},
   "source": [
    "## Let's see it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0040c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177fb50",
   "metadata": {},
   "source": [
    "### original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca26df16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Paul Erdős and George Pólya were influential Hungarian mathematicians who contributed a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = \"Paul Erdős and George Pólya were influential Hungarian mathematicians who contributed \\\n",
    "a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), \\\n",
    "but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\"\n",
    "original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b9a0d",
   "metadata": {},
   "source": [
    "### 1. lowercase text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91138f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdős and george pólya were influential hungarian mathematicians who contributed a lot to the field. erdős's name contains the hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as erdos or erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = original.lower()\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609841c",
   "metadata": {},
   "source": [
    "### 2. remove any accented characters and non-ASCII characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf0003d",
   "metadata": {},
   "source": [
    "- `unicodedata.normalize` removes any inconsistencies in unicode character encoding\n",
    "- `.encode` to convert the resulting string to the ASCII character set\n",
    "- `.decode` to turn the resulting bytes object back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3070e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import unicode character database\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db40fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya were influential hungarian mathematicians who contributed a lot to the field. erdos's name contains the hungarian letter 'o' ('o' with double acute accent), but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = unicodedata.normalize('NFKD', article)\\\n",
    ".encode('ascii', 'ignore')\\\n",
    ".decode('utf-8')\n",
    "\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6eed33",
   "metadata": {},
   "source": [
    "### 3. remove special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395fcc61",
   "metadata": {},
   "source": [
    "- remove anything that isn't a-z, a number, a single quote, or a whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdadfa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import regular expression operations\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abc12d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya were influential hungarian mathematicians who contributed a lot to the field erdos's name contains the hungarian letter 'o' 'o' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use re.sub to remove special characters\n",
    "article = re.sub(r'[^a-z0-9\\'\\s]', '', article)\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54588fc0",
   "metadata": {},
   "source": [
    "### 4. tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d02af",
   "metadata": {},
   "source": [
    "Tokenization is the process of breaking something down into smaller, discrete units. These units are called tokens.\n",
    "\n",
    "It's common to tokenize the strings to break up words and punctutation left over into discrete units. \n",
    "\n",
    "Use `nltk.tokenize.ToktokTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d500d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import natural language toolkit\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6edbadf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.tokenize.toktok.ToktokTokenizer at 0x14ecab100>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the tokenizer\n",
    "tokenize = nltk.tokenize.ToktokTokenizer()\n",
    "tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ac95470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya were influential hungarian mathematicians who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the tokenizer\n",
    "article = tokenize.tokenize(article, return_str=True)\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1742c1",
   "metadata": {},
   "source": [
    "### 5. stem or lemmatize words (choose one!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219029f",
   "metadata": {},
   "source": [
    "Stemming\n",
    "- **truncates** words to their \"stem\"\n",
    "- algorithmic rules (non lingustic)\n",
    "- example: \"calls\", \"called\", \"calling\" --> \"call\"\n",
    "- fast and efficient\n",
    "\n",
    "\n",
    "Lemmatize\n",
    "- **changes** words to their \"root\"\n",
    "- it can conjugate to the base word \n",
    "- example: \"mouse\", \"mice\" --> \"mouse\"\n",
    "- slower than stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528b8ef",
   "metadata": {},
   "source": [
    "#### stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01222806",
   "metadata": {},
   "source": [
    "Use `nltk.porter.PorterStemmer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24ba38de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PorterStemmer>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create porter stemmer\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82efa3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('call', 'call', 'call')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test stemmer\n",
    "ps.stem('calling'), ps.stem('calls'), ps.stem('called')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a76322cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya were influential hungarian mathematicians who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necess\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "859a9ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdo',\n",
       " 'and',\n",
       " 'georg',\n",
       " 'polya',\n",
       " 'were',\n",
       " 'influenti',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'who']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use stemmer - apply stem to each word in our string\n",
    "stems = [ps.stem(word) for word in article.split()]\n",
    "stems[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "745a851a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdo and georg polya were influenti hungarian mathematician who contribut a lot to the field erdo ' s name contain the hungarian letter ' o ' ' o ' with doubl acut accent but is often incorrectli written as erdo or erdo either by mistak or out of typograph necess\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join words back together\n",
    "article_stemmed = ' '.join(stems)\n",
    "article_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5796580c",
   "metadata": {},
   "source": [
    "#### lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04433964",
   "metadata": {},
   "source": [
    "Use `nltk.stem.WordNetLemmatizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70f729f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the first time\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c66a37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordNetLemmatizer>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the lemmatizer\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "wnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2437772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mouse', 'mouse')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test lemmatizer\n",
    "wnl.lemmatize('mouses'), wnl.lemmatize('mice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eca5d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya were influential hungarian mathematicians who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40a74ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdos',\n",
       " 'and',\n",
       " 'george',\n",
       " 'polya',\n",
       " 'were',\n",
       " 'influential',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'who']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use lemmatize - apply stem to each word in our string\n",
    "lemmas = [wnl.lemmatize(word) for word in article.split()]\n",
    "lemmas[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01ae7377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya were influential hungarian mathematician who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written a erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join words back together\n",
    "article_lemmatized = ' '.join(lemmas)\n",
    "article_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c918a833",
   "metadata": {},
   "source": [
    "### 6. remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055beaaa",
   "metadata": {},
   "source": [
    "Words which have little or no significance, especially when constructing meaningful features from text, are known as stopwords\n",
    "- example: a, an, the, and like\n",
    "\n",
    "We will use a standard English language stopwords list from nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfedf6",
   "metadata": {},
   "source": [
    "Use `nltk.corpus.stopwords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bd9461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our stopwords list\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e450dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mistygarcia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only need to do once\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a67608c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save stopwords\n",
    "stopwords_ls = stopwords.words('english')\n",
    "stopwords_ls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74ad6714",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_ls.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f49b1605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_ls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cab006a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all', 'about', 'after']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra = ['all','about','after']\n",
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60f416b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'\",\n",
       " 'a',\n",
       " 'above',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords_ls) - set(extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9629de0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_ls[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a69b25ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'am' in stopwords_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cec7d62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be82d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to stopword list\n",
    "stopwords_ls.append('o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf84eb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7eebf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove from stopword list\n",
    "stopwords_ls.remove('o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39d208d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6cd4b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdos',\n",
       " 'and',\n",
       " 'george',\n",
       " 'polya',\n",
       " 'were',\n",
       " 'influential',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'who']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split words in lemmatized article\n",
    "words = article_lemmatized.split()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1ef6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to stopword list\n",
    "stopwords_ls.append(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "edb4bb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdos',\n",
       " 'george',\n",
       " 'polya',\n",
       " 'influential',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'contributed',\n",
       " 'lot',\n",
       " 'field',\n",
       " 'erdos',\n",
       " 'name',\n",
       " 'contains',\n",
       " 'hungarian',\n",
       " 'letter',\n",
       " 'double',\n",
       " 'acute',\n",
       " 'accent',\n",
       " 'often',\n",
       " 'incorrectly',\n",
       " 'written',\n",
       " 'erdos',\n",
       " 'erdos',\n",
       " 'either',\n",
       " 'mistake',\n",
       " 'typographical',\n",
       " 'necessity']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stopwords from list of words\n",
    "filtered_words = [word for word in words if word not in stopwords_ls]\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01341d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show how many words we removed\n",
    "len(words) - len(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a26966e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdos george polya influential hungarian mathematician contributed lot field erdos name contains hungarian letter double acute accent often incorrectly written erdos erdos either mistake typographical necessity'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join words back together\n",
    "parsed_article = ' '.join(filtered_words)\n",
    "parsed_article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c7dffe",
   "metadata": {},
   "source": [
    "#### ready for exploration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec1bddfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Paul Erdős and George Pólya were influential Hungarian mathematicians who contributed a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7afa7535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdos george polya influential hungarian mathematician contributed lot field erdos name contains hungarian letter double acute accent often incorrectly written erdos erdos either mistake typographical necessity'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a227c7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
